{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab68611b",
   "metadata": {},
   "source": [
    "# 05 – Play Style Clustering\n",
    "\n",
    "Group team-seasons into style clusters using pace, efficiency, shooting, and ball movement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04e87e4",
   "metadata": {},
   "source": [
    "## Goals\n",
    "- Standardize key style features and fit K-Means to reveal distinct archetypes.\n",
    "- Profile clusters by era and success rate.\n",
    "- Visualize clusters on 2D projections (e.g., pace vs three-point rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9602f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if PROJECT_ROOT.name == 'notebooks':\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from src.pipeline.season_summary import generate_team_season_summary\n",
    "from src.data_ingest import NBADataIngestor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a8a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load team-season data.\n",
    "summary_path = Path(\"data/processed/team_season_regular.csv\")\n",
    "if summary_path.exists():\n",
    "    summary = pd.read_csv(summary_path)\n",
    "else:\n",
    "    ingestor = NBADataIngestor()\n",
    "    summary = generate_team_season_summary(ingestor, regular_season_only=True, save=False)\n",
    "\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f17508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature matrix for clustering.\n",
    "feature_cols = [\n",
    "    \"PACE\",\n",
    "    \"OFF_EFF_PER_100\",\n",
    "    \"DEF_EFF_PER_100\",\n",
    "    \"THREE_POINT_RATE\",\n",
    "    \"AST_TOV_RATIO\",\n",
    "]\n",
    "\n",
    "data = summary.dropna(subset=feature_cols).reset_index(drop=True)\n",
    "X = data[feature_cols]\n",
    "\n",
    "# Choose cluster count via silhouette scan.\n",
    "scores = {}\n",
    "for k in range(3, 8):\n",
    "    model = make_pipeline(StandardScaler(), KMeans(n_clusters=k, n_init=20, random_state=42))\n",
    "    labels = model.fit_predict(X)\n",
    "    scores[k] = silhouette_score(X, labels)\n",
    "\n",
    "display(pd.DataFrame.from_dict(scores, orient=\"index\", columns=[\"silhouette\"]).rename_axis(\"k\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c039d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit final model (pick k based on silhouette peak).\n",
    "optimal_k = max(scores, key=scores.get)\n",
    "cluster_model = make_pipeline(StandardScaler(), KMeans(n_clusters=optimal_k, n_init=50, random_state=42))\n",
    "labels = cluster_model.fit_predict(X)\n",
    "\n",
    "data[\"CLUSTER\"] = labels\n",
    "centers = cluster_model.named_steps[\"kmeans\"].cluster_centers_\n",
    "centers_df = pd.DataFrame(centers, columns=feature_cols)\n",
    "centers_df[\"CLUSTER\"] = range(optimal_k)\n",
    "centers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8259b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters on key planes.\n",
    "palette = sns.color_palette(\"tab10\", n_colors=optimal_k)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    x=\"PACE\",\n",
    "    y=\"THREE_POINT_RATE\",\n",
    "    hue=\"CLUSTER\",\n",
    "    palette=palette,\n",
    "    alpha=0.7,\n",
    "    ax=axes[0],\n",
    ")\n",
    "axes[0].set_title(\"Pace vs 3P Rate by Cluster\")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=data,\n",
    "    x=\"OFF_EFF_PER_100\",\n",
    "    y=\"DEF_EFF_PER_100\",\n",
    "    hue=\"CLUSTER\",\n",
    "    palette=palette,\n",
    "    alpha=0.7,\n",
    "    ax=axes[1],\n",
    ")\n",
    "axes[1].set_title(\"Off vs Def Efficiency by Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9852ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster prevalence by era and win rate.\n",
    "if {\"ERA_LABEL\", \"WIN_PCT\"}.issubset(data.columns):\n",
    "    cluster_era = (\n",
    "        data.groupby([\"ERA_LABEL\", \"CLUSTER\"])\n",
    "        .agg(count=(\"TEAM_ID\", \"size\"), avg_win=(\"WIN_PCT\", \"mean\"))\n",
    "        .reset_index()\n",
    "    )\n",
    "    display(cluster_era.sort_values([\"ERA_LABEL\", \"CLUSTER\"]))\n",
    "\n",
    "# Save assignments for reuse if desired.\n",
    "assignments_path = Path(\"data/processed/team_clusters.csv\")\n",
    "data[[\"TEAM_ID\", \"SEASON_YEAR\", \"CLUSTER\"]].to_csv(assignments_path, index=False)\n",
    "print(f\"Cluster assignments saved to {assignments_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b9d7fc",
   "metadata": {},
   "source": [
    "### Gaussian Mixture sanity check\n",
    "Soft clustering alternative for reporting and to test cluster robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdafd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit GMM across candidate cluster counts using BIC/AIC.\n",
    "gmm_scores = []\n",
    "for k in range(3, 8):\n",
    "    gmm = make_pipeline(StandardScaler(), GaussianMixture(n_components=k, random_state=42, n_init=5))\n",
    "    gmm.fit(X)\n",
    "    bic = gmm.named_steps[\"gaussianmixture\"].bic(X)\n",
    "    aic = gmm.named_steps[\"gaussianmixture\"].aic(X)\n",
    "    gmm_scores.append({\"k\": k, \"bic\": bic, \"aic\": aic})\n",
    "\n",
    "gmm_df = pd.DataFrame(gmm_scores).set_index(\"k\")\n",
    "gmm_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3eed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Responsibilities for the best BIC model.\n",
    "best_k = gmm_df[\"bic\"].idxmin()\n",
    "best_gmm = make_pipeline(StandardScaler(), GaussianMixture(n_components=int(best_k), random_state=42, n_init=10))\n",
    "best_gmm.fit(X)\n",
    "probs = best_gmm.named_steps[\"gaussianmixture\"].predict_proba(X)\n",
    "\n",
    "data_gmm = data.copy()\n",
    "data_gmm[[f\"GMM_{i}\" for i in range(int(best_k))]] = probs\n",
    "\n",
    "# 2D PCA projection colored by argmax responsibility.\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "coords = pca.fit_transform(StandardScaler().fit_transform(X))\n",
    "data_gmm[\"PC1\"], data_gmm[\"PC2\"] = coords[:, 0], coords[:, 1]\n",
    "data_gmm[\"GMM_LABEL\"] = probs.argmax(axis=1)\n",
    "\n",
    "sns.scatterplot(data=data_gmm, x=\"PC1\", y=\"PC2\", hue=\"GMM_LABEL\", palette=\"tab10\", alpha=0.7)\n",
    "plt.title(f\"GMM responsibilities (k={best_k})\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d45154",
   "metadata": {},
   "source": [
    "### K-Means stability across seeds\n",
    "Check silhouette variation to report robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b76ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stability = []\n",
    "for seed in [1, 7, 21, 42, 84]:\n",
    "    model = make_pipeline(StandardScaler(), KMeans(n_clusters=optimal_k, n_init=20, random_state=seed))\n",
    "    labels_seed = model.fit_predict(X)\n",
    "    stability.append({\"seed\": seed, \"silhouette\": silhouette_score(X, labels_seed)})\n",
    "\n",
    "stability_df = pd.DataFrame(stability).sort_values(\"silhouette\", ascending=False)\n",
    "stability_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ed8ee7",
   "metadata": {},
   "source": [
    "### Case study table (cluster exemplars)\n",
    "Top win% team-seasons per cluster for narrative examples in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a3f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_rows = []\n",
    "for cluster_id in sorted(data[\"CLUSTER\"].unique()):\n",
    "    cluster_slice = data[data[\"CLUSTER\"] == cluster_id]\n",
    "    top = cluster_slice.sort_values(\"WIN_PCT\", ascending=False).head(2)\n",
    "    for _, row in top.iterrows():\n",
    "        case_rows.append(\n",
    "            {\n",
    "                \"cluster\": cluster_id,\n",
    "                \"team\": row.get(\"TEAM_ID\", \"NA\"),\n",
    "                \"season\": int(row.get(\"SEASON_YEAR\", 0)),\n",
    "                \"win_pct\": row.get(\"WIN_PCT\", np.nan),\n",
    "                \"pace\": row.get(\"PACE\", np.nan),\n",
    "                \"three_pt_rate\": row.get(\"THREE_POINT_RATE\", np.nan),\n",
    "            }\n",
    "        )\n",
    "\n",
    "case_table = pd.DataFrame(case_rows).sort_values([\"cluster\", \"win_pct\"], ascending=[True, False])\n",
    "case_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efe530d",
   "metadata": {},
   "source": [
    "These outputs (GMM BIC/AIC, seed stability, exemplar teams) can be dropped into LaTeX tables to satisfy the rubric’s comparison and case-study expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9063a161",
   "metadata": {},
   "source": [
    "### Cluster transitions by franchise\n",
    "Track how selected franchises move across clusters over time for narrative context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2989a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count cluster switches per team and show a few exemplars.\n",
    "team_switches = (\n",
    "    data.sort_values([\"TEAM_ID\", \"SEASON_YEAR\"])\n",
    "    .groupby(\"TEAM_ID\")\n",
    "    .apply(lambda df: (df[\"CLUSTER\"].diff().ne(0)).sum())\n",
    "    .reset_index(name=\"cluster_switches\")\n",
    "    .sort_values(\"cluster_switches\", ascending=False)\n",
    ")\n",
    "team_switches.head()\n",
    "\n",
    "# Plot transitions for a handful of franchises if available.\n",
    "watch_list = [\"GSW\", \"HOU\", \"SAS\", \"BOS\", \"LAL\", \"DAL\"]\n",
    "plot_df = data[data[\"TEAM_ID\"].isin(watch_list)].copy()\n",
    "if not plot_df.empty:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    for team, group in plot_df.groupby(\"TEAM_ID\"):\n",
    "        ax.plot(group[\"SEASON_YEAR\"], group[\"CLUSTER\"], marker=\"o\", label=team)\n",
    "    ax.set_ylabel(\"Cluster ID\")\n",
    "    ax.set_xlabel(\"Season year\")\n",
    "    ax.set_title(\"Cluster transitions for selected franchises\")\n",
    "    ax.legend(ncol=3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No watch-list teams present in the dataset sample.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40198c31",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Try alternative clustering (Gaussian Mixture, HDBSCAN) to capture soft boundaries.\n",
    "- Include defensive profile features (opponent 3P rate, turnover forcing) if available.\n",
    "- Track cluster transitions for franchises over time to narrate stylistic evolution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
